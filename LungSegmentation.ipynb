{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LungSegmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaeSKj5TDh/gC9WlrbTmf6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-parida12/furry-octo-spork/blob/main/LungSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zJtyUDbni9F"
      },
      "source": [
        "# Hands on ML Segmentation Session\n",
        "\n",
        "The purpose of the notebook is to follow the lifecycle of creating a deep learning based algorithm for the task of segmentation. The task we will focus on is the segmentation of the left and right lungs in a CXR image.\n",
        "\n",
        "We will be using the data from the kaggle dataset from the CXR segmentation challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcjsrPnEfTtz"
      },
      "source": [
        "# Getting The Playground Ready\n",
        "\n",
        "Some of the steps to get the colab ready. In this section we will download the data from the kaggle and make the colab enviornment ready for the further tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O87PaSYlQeNP"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# configure the kaggle downloader api\n",
        "path_to_json = ??\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = str(Path(path_to_json).parent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnMPT88l8LRI"
      },
      "source": [
        "\n",
        "# confirm TensorFlow sees the GPU\n",
        "from tensorflow.python.client import device_lib\n",
        "assert 'GPU' in str(device_lib.list_local_devices())\n",
        "print('All Good! GPU found!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6r1zMiyQp44"
      },
      "source": [
        "# Download the dataset from kaggle\n",
        "!kaggle datasets download -d nikhilpandey360/chest-xray-masks-and-labels\n",
        "# unzip the images \n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yboM8aLffgER"
      },
      "source": [
        "# Image Loading and Processing\n",
        "\n",
        "This section is used to learn to load the data. The data, which are images undergo various processing to be able to train a model. The processing we focus here are- resizing the image to a standard size and normalising the image across the dataset.\n",
        "\n",
        "### Learning Targets-\n",
        "\n",
        "*   Reading Image data\n",
        "*   Resizing the Image\n",
        "*   Min-Max Normalisation of a Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bjya4uVRrvY"
      },
      "source": [
        "data_path = \"/content/\"  # directory where the Lung Segmentation folder is located\n",
        "\n",
        "# load the image paths and mask paths\n",
        "lung_image_paths = glob(os.path.join(data_path,\"Lung Segmentation/CXR_png/*.png\"))\n",
        "mask_image_paths = glob(os.path.join(data_path,\"Lung Segmentation/masks/*.png\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcMNZbTGR005"
      },
      "source": [
        "related_paths = defaultdict(list)\n",
        "\n",
        "# finding the annotation for a image to build the image-annotation pairs for training \n",
        "# building a hashmap of image annotation paris\n",
        "for img_path in lung_image_paths:\n",
        "    img_match = re.search(\"CXR_png/(.*)\\.png$\", img_path)\n",
        "    if img_match:\n",
        "        img_name = img_match.group(1)\n",
        "    for mask_path in mask_image_paths:\n",
        "        mask_match = re.search(img_name, mask_path)\n",
        "        if mask_match:\n",
        "            related_paths[\"image_path\"].append(img_path)\n",
        "            related_paths[\"mask_path\"].append(mask_path)\n",
        "# store the hashmap as a pandas dataframe for easy reading\n",
        "paths_df = pd.DataFrame.from_dict(related_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP1Pm8y6Wdtb"
      },
      "source": [
        "# lets see how the image-mask path pairing looks like\n",
        "print(paths_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLqFDzBSY_K"
      },
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "# process the data to make it train ready\n",
        "for xray_num in range (len(paths_df)):\n",
        "\n",
        "    img_path = paths_df[\"image_path\"][xray_num]\n",
        "    mask_path = paths_df[\"mask_path\"][xray_num]\n",
        "\n",
        "    # read the 3 channel image and resize it to (256, 256, 3)\n",
        "    img = ## read an image ##\n",
        "    img = ## resize the image ##\n",
        "    \n",
        "    # bring the img from pixel value [0,255] -> [0,1]\n",
        "    assert img.shape == (256, 256, 3)\n",
        "    img = ## normalise the image ##\n",
        "    \n",
        "    # read the single channel mask and resize it to (256, 256)\n",
        "    mask = ## read an image ##\n",
        "    mask = ## resize the image ##\n",
        "    mask = ## make single channel ##\n",
        "\n",
        "    # bring the mask from pixel value [0,255] -> [0,1]\n",
        "    assert mask.shape == (256, 256)\n",
        "    mask= ## normalise the image ##\n",
        "\n",
        "    x_train.append(img)\n",
        "    y_train.append(mask)\n",
        "\n",
        "assert len(x_train)== len(y_train) == 704 == len(paths_df)\n",
        "print (f\"Image {i+1} added\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFiRpRaQ69fI"
      },
      "source": [
        "# let us see some image-mask pairing\n",
        "for i in range (5):\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize = (10,10))\n",
        "    ax1 = fig.add_subplot(2,2,1)\n",
        "    ax1.imshow(x_train[i], cmap = \"gray\")\n",
        "    ax2 = fig.add_subplot(2,2,2)\n",
        "    ax2.imshow(y_train[i], cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvVB-jQK_hw1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dJmIlGfYvEe"
      },
      "source": [
        "# defining the image shape based on the pre-processing done above\n",
        "input_shape = (??,?? ,?? ) ## fill in the size of the input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aRTziWbfIO-"
      },
      "source": [
        "## Deep Learning Begins Here\n",
        "\n",
        "This section is used to get to know more about the training of deep learning methods. We go through the steps of building a deep neural netweork, selecting the correct loss function and optimisers.\n",
        "\n",
        "The model is then put through a training process and the ideal model is saved for the inference.\n",
        "\n",
        "### Learning Targets-\n",
        "\n",
        "\n",
        "*   Building Layers in a Deep Neural Network(DNN)\n",
        "*   Selecting Hyperparameters for a Network\n",
        "*   Training a DNN\n",
        "*   Saving the trained DNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM2n3ay9geG7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import * \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfixDBVM7eeq"
      },
      "source": [
        "# to measure the overfitting of a model we create a training and validation set\n",
        "# split the dataset into train and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=??) # fill in the split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in6ro9twcDY7"
      },
      "source": [
        "# defination of the deep learning based segmentor\n",
        "def Segmenter(input_size=(256, 256, 1), latent_dim = 8):\n",
        "    # Input Layer\n",
        "    input_img = Input(shape=input_shape, name='encoder_input')\n",
        "    \n",
        "    # Encoder \n",
        "    # Conv2D(features, (kernelsize, kernelsize), padding_type, activation_layer)\n",
        "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(input_img)\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu',strides=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = ?? # a conv layer here. Recomendation: feature 128, kernel_size(3, 3), same padding, relu activation \n",
        "    conv_shape = K.int_shape(x) \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    # Latent Space\n",
        "    z = Dense(latent_dim, name='latent_vector')(x)\n",
        "    \n",
        "    # Decoder\n",
        "    x = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(z)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), padding='same', activation='relu',strides=(2, 2))(x)\n",
        "    output = ?? # a conv transpose layer here. Recomendation: feature 1, kernel_size(3, 3), same padding, sigmoid activation \n",
        "    \n",
        "\n",
        "    model = Model(inputs = input_img, outputs = output)\n",
        "    # define the model optimiser, losses and metrics\n",
        "    #https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
        "    model.compile(optimizer = ?? , loss = ??, metrics = [??])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dt00WWCe4uD"
      },
      "source": [
        "# load the model\n",
        "model = Segmenter(input_shape)\n",
        "# model layer by layer summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4cOCZgTe7ll"
      },
      "source": [
        "# some more model viz\n",
        "tf.keras.utils.plot_model(model, to_file=\"model.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84GmaVR8fBo7"
      },
      "source": [
        "# early stopping to prevent overfitting\n",
        "model_checkpoint = ModelCheckpoint(\"/content/trained_model.h5\", monitor='loss',verbose=2, save_best_only=True)\n",
        "\n",
        "# tain the model\n",
        "history = model.fit(x = np.array(x_train), \n",
        "                    y = np.array(y_train), \n",
        "                    epochs = ??, \n",
        "                    batch_size = ??,\n",
        "                    validation_data=(np.array(x_val), np.array(y_val)),\n",
        "                    callbacks = [model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3mzHbX6oYC"
      },
      "source": [
        "# lets take a look how model training went\n",
        "\n",
        "# plot training vs validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# plot training vs validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW04KEQC3GAb"
      },
      "source": [
        "# Inference\n",
        "\n",
        "This section is used to get to know how to use a trained a model to do inference. We go through the steps loading the pre-trained model and doing a prediction.\n",
        "\n",
        "### Learning Targets-\n",
        "\n",
        "*   Loading a trained model\n",
        "*   Doing a inference on a Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ_dPZyimkxt"
      },
      "source": [
        "# if your trained model is not good enough you can use a pre-trained model\n",
        "! wget https://github.com/a-parida12/furry-octo-spork/raw/main/solution/trained_model.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI9FPpY23KM5"
      },
      "source": [
        "# loading the model\n",
        "pretrained_weights_path = ??\n",
        "model = Segmenter(input_shape)\n",
        "\n",
        "# adding weights from the pretrained model\n",
        "model.load_weights(pretrained_weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScBIZqUF4jLf"
      },
      "source": [
        "test_path_dir = os.path.join(data_path,\"Lung Segmentation/test/\")\n",
        "test_images = os.listdir(os.path.join(data_path,\"Lung Segmentation/test/\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BI3Xb585Txj"
      },
      "source": [
        "# load the data and do the same preprocessing as the training data\n",
        "x_test=[]\n",
        "for i in range (len(test_images)):\n",
        "    xray_num = i\n",
        "    test_path = test_path_dir + test_images[xray_num]\n",
        "\n",
        "    img = cv2.imread(test_path)\n",
        "    img = cv2.resize(img,(256,256))\n",
        "    img = img/255\n",
        "    x_test.append(img)\n",
        "print (f\"Image {i+1} added\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvO6oYVw54H3"
      },
      "source": [
        "# inference\n",
        "x_test= np.array(x_test)\n",
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZmrjn35qAS"
      },
      "source": [
        "# let us visualise the outputs for the test set\n",
        "for i in range (15,20):\n",
        "    fig = plt.figure(figsize = (10,10))\n",
        "\n",
        "    ax1 = fig.add_subplot(2,2,1)\n",
        "    ax1.imshow(x_test[i], cmap = \"gray\")\n",
        "    ax2 = fig.add_subplot(2,2,2)\n",
        "    ax2.imshow(np.squeeze(y_pred[i]), cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFMwtjDG5xry"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}